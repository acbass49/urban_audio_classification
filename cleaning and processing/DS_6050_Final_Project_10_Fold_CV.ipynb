{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# DS 6050 Final Project 10 Fold CV Code\n",
        "### Connie Cui"
      ],
      "metadata": {
        "id": "tfUAirNER6Ky"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set up\n",
        "\n",
        "Need the following files:\n",
        "- All_folds.csv\n",
        "- test_data.csv\n",
        "- test_labels.csv\n",
        "- train_data.csv\n",
        "- train_labels.csv"
      ],
      "metadata": {
        "id": "_uvrGLfoR6mg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Load necessary libraries ###\n",
        "import glob\n",
        "import os\n",
        "import librosa\n",
        "import librosa.display\n",
        "import skimage\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "pd.plotting.register_matplotlib_converters()\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D, Dropout\n",
        "from tensorflow.keras.utils import to_categorical "
      ],
      "metadata": {
        "id": "5XAWRAQ0Qk7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv(\"train_data.csv\", header = None)\n",
        "test_data = pd.read_csv(\"test_data.csv\", header = None)\n",
        "train_lab = pd.read_csv(\"train_labels.csv\", header = None)\n",
        "test_lab = pd.read_csv(\"test_labels.csv\", header = None)"
      ],
      "metadata": {
        "id": "9GC3ULv3Uh80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data)+len(test_data)\n",
        "# should have 8732, need to make sure we dont have one of the rows as the header \n",
        "# since we are importing what was previously a np array to csv/df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzgRT8VCWS9q",
        "outputId": "c678dbe8-4de1-4a58-d7f9-b43ed194196b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8730"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=pd.concat([train_data, test_data]) # .to_numpy().reshape(8732, 40, 5, 1)\n",
        "Y=pd.concat([train_lab,test_lab]) # .to_numpy().reshape(8732,)"
      ],
      "metadata": {
        "id": "TPxsTSwNUr7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folds = pd.read_csv(\"All_folds.csv\", header=None)\n",
        "folds.columns = ['folds']\n",
        "folds['folds'] = folds['folds'].astype('int')"
      ],
      "metadata": {
        "id": "prdJp_wyXuoM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdb1ab03-954c-4394-d8f6-fc10e0f65fb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    float64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Train and evaluate via 10-Folds cross-validation ###\n",
        "accuracies = []\n",
        "\n",
        "for i in range(1, 11):  # 1-10 to match values in folds df\n",
        "  # obtain train and test indices\n",
        "  test_idx = list(np.where(folds['folds'] == i)[0]) # find all indices for fold i and set as test indices\n",
        "  train_idx = list(np.setdiff1d(folds.index.to_numpy(), np.where(folds['folds'] == i)[0])) # everything except fold i as train indices\n",
        "  \n",
        "  # use train and test indices to create train and test x/y and reshape them for training our model\n",
        "  x_train = X.iloc[train_idx].to_numpy().reshape(len(train_idx), 40, 5, 1)\n",
        "  y_train = Y.iloc[train_idx].to_numpy().reshape(len(train_idx),)\n",
        "  x_test = X.iloc[test_idx].to_numpy().reshape(len(test_idx), 40, 5, 1)\n",
        "  y_test = Y.iloc[test_idx].to_numpy().reshape(len(test_idx),)\n",
        "\n",
        "  # insert model architecture here (just put the alexnet for reference, will need to update this for each model)\n",
        "  pool_size = (2, 2)\n",
        "  kernel_size = (3, 3)\n",
        "  input_shape = (40, 5, 1)\n",
        "  num_classes = 10\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(64, (3, 3), padding = \"same\", activation = \"tanh\", input_shape = input_shape))\n",
        "  model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "  model.add(Conv2D(128, (3, 3), padding = \"same\", activation = \"tanh\"))\n",
        "  model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.1))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(1024, activation = \"tanh\"))\n",
        "  model.add(Dense(10, activation = \"softmax\"))\n",
        "\n",
        "  optimizer = keras.optimizers.Adam(lr=1e-4)\n",
        "  model.compile(optimizer = optimizer, loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "  model.fit(x_train, y_train, epochs = 50, batch_size = 50, validation_data = (x_test, y_test))\n",
        "\n",
        "\n",
        "  # add accuracy to our accuracies list for comparison\n",
        "  accuracies.append(model.evaluate(x_test, y_test)[1])\n",
        "  # index 0 is validation loss in final epoch, index 1 is validation accuracy in final epoch\n",
        "  # if we try and look into other metrics, they may be in a different index and \n",
        "  # we would need ot make a separate list for those metrics\n",
        "\n"
      ],
      "metadata": {
        "id": "zniy1fikzTO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fold_acc = pd.DataFrame(list(zip(range(1,11), accuracies)),\n",
        "                        columns =['Folds', 'Validation Accuracy']) \n",
        "\n",
        "fold_acc\n",
        "\n",
        "## if looking into multiple models, make sure to create multiple accuracy lists and can add them in this \n",
        "# dataframe as well for side by side comparison of diff models and their accuracies by fold"
      ],
      "metadata": {
        "id": "PF7Qtg8lXuqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-snBtP4RXutg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}